{
  "adam_epsilon": 1e-08,
  "always_truncate_tail": false,
  "attention_probs_dropout_prob": 0.1,
  "config_name": "",
  "data_dir": "data/",
  "do_eval": false,
  "do_lower_case": true,
  "do_train": true,
  "eval_batch_size": 64,
  "fp16": false,
  "fp16_opt_level": "O1",
  "gradient_accumulation_steps": 1,
  "hidden_dropout_prob": 0.1,
  "label_smoothing": 0,
  "learning_rate": 2e-05,
  "local_rank": -1,
  "log_dir": "",
  "logging_steps": 100,
  "mask_prob": 0.2,
  "mask_prob_eos": 0,
  "mask_source_words": false,
  "mask_whole_word": false,
  "max_grad_norm": 1.0,
  "max_len_a": 0,
  "max_len_b": 0,
  "max_position_embeddings": 512,
  "max_pred": 20,
  "max_seq_length": 128,
  "model_name_or_path": "unilm_model/",
  "model_recover_path": null,
  "model_type": "unilm",
  "no_cuda": false,
  "num_train_epochs": 5.0,
  "num_workers": 0,
  "optim_recover_path": null,
  "output_dir": "E:/jiann_wenda_model/",
  "seed": 42,
  "skipgram_prb": 0.0,
  "skipgram_size": 1,
  "src_file": "egret_wenda_lines.json",
  "tokenized_input": false,
  "tokenizer_name": "",
  "train_batch_size": 32,
  "trunc_seg": "",
  "warmup_proportion": 0.1,
  "weight_decay": 0.01
}